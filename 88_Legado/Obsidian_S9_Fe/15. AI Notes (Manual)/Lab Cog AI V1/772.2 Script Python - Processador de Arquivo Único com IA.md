```
# -*- coding: utf-8 -*-
import os
import pathlib
import re
import frontmatter
import logging
import shutil
from google import genai
from google.genai import types
import time
from datetime import datetime
import argparse # Para lidar com argumentos da linha de comando

# --- Configuração Inicial ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
VAULT_PATH = pathlib.Path(r"C:\Lab_Cognitivo_Script\Obsidian_S9_Fe") # Raiz do Vault
NOTE_EXTENSIONS = ['.md']
# --- NOVO: Configuração da Pasta de Saída ---
OUTPUT_FOLDER_RELATIVE_PATH = "15. AI Output" # Pasta para salvar os resultados

# --- Configuração da API Gemini ---
# ####################################################################
# ### ATENÇÃO! API KEY HARDCODED ABAIXO!                           ###
# ### ... (Avisos de segurança mantidos) ...                       ###
# ####################################################################
HARDCODED_API_KEY = "AIzaSyDWG30FYAUc6XyVCv71vnR50pjWF-aN7i8" # <--- CHAVE INSERIDA DIRETAMENTE!

# Instancia o cliente da API
client: genai.Client | None = None
# ... (Lógica de inicialização do cliente mantida) ...
if not HARDCODED_API_KEY or HARDCODED_API_KEY == "SUA_CHAVE_API_REAL_AQUI":
     logging.error("### ERRO CRÍTICO: API Key está vazia ou não foi substituída! ###")
     client = None
else:
    try:
        client = genai.Client(api_key=HARDCODED_API_KEY)
        client.models.list() # Verifica a autenticação
        logging.info("Cliente da API Gemini inicializado com sucesso (usando chave HARDCODED - NÃO SEGURO!).")
    except Exception as e:
        logging.error(f"Erro CRÍTICO ao inicializar o cliente da API Gemini com a chave fornecida: {e}.")
        client = None

# Modelo Gemini a ser usado
GEMINI_MODEL_NAME = "models/gemini-1.5-pro"

# --- Funções Auxiliares ---

def read_note_content(note_path: pathlib.Path) -> tuple[dict, str | None] | tuple[None, None]:
    """Lê o conteúdo e frontmatter de uma nota."""
    # ... (código inalterado da v19) ...
    try:
        # Lê o conteúdo completo sempre que chamado nesta versão
        post = frontmatter.load(note_path, encoding='utf-8')
        content = post.content
        return post.metadata, content
    except FileNotFoundError:
        logging.error(f"Erro: Arquivo não encontrado {note_path}")
        return None, None
    except UnicodeDecodeError:
        logging.warning(f"Erro de decodificação UTF-8 no arquivo {note_path}. Tentando com latin-1...")
        try:
            post = frontmatter.load(note_path, encoding='latin-1')
            content = post.content
            logging.info(f"Leitura bem-sucedida de {note_path.name} com latin-1.")
            return post.metadata, content
        except Exception as e_alt:
            logging.error(f"Erro ao ler {note_path} mesmo com codificação alternativa: {e_alt}")
            return None, None
    except frontmatter.YAMLParseError as e_yaml:
         logging.error(f"Erro ao parsear o frontmatter YAML no arquivo {note_path}: {e_yaml}")
         # Tenta retornar apenas o conteúdo bruto se o YAML falhar?
         try:
             content = note_path.read_text(encoding='utf-8')
             logging.warning(f"YAML inválido, mas conteúdo lido de {note_path.name}")
             return {}, content # Retorna metadados vazios
         except Exception:
             logging.error(f"Falha ao ler conteúdo bruto de {note_path.name} após erro de YAML.")
             return None, None
    except Exception as e:
        logging.error(f"Erro inesperado ao ler ou parsear a nota {note_path}: {e}")
        return None, None

# --- Função de IA Genérica ---
def process_content_with_gemini(
    genai_client: genai.Client,
    input_content: str,
    prompt_instructions: str,
    input_filename: str # Apenas para logging
) -> str | None:
    """
    Chama a API Gemini para processar um conteúdo de entrada com instruções de um prompt.

    Args:
        genai_client: O objeto genai.Client inicializado.
        input_content: O conteúdo do arquivo a ser processado.
        prompt_instructions: As instruções lidas do arquivo de prompt.
        input_filename: O nome do arquivo de entrada (para logging).

    Returns:
        A resposta de texto da API Gemini, ou None em caso de erro.
    """
    if not genai_client:
        logging.warning("Cliente da API Gemini não inicializado. Pulando chamada.")
        return None

    # Combina as instruções do prompt com o conteúdo de entrada
    # (Pode precisar ajustar este formato dependendo da complexidade do prompt)
    contents = [
        f"{prompt_instructions}\n\n**Conteúdo de Entrada para Processar:**\n---\n{input_content}\n---"
    ]

    safety_settings_types = [
        types.SafetySetting(category='HARM_CATEGORY_HARASSMENT', threshold='BLOCK_MEDIUM_AND_ABOVE'),
        types.SafetySetting(category='HARM_CATEGORY_HATE_SPEECH', threshold='BLOCK_MEDIUM_AND_ABOVE'),
        types.SafetySetting(category='HARM_CATEGORY_SEXUALLY_EXPLICIT', threshold='BLOCK_MEDIUM_AND_ABOVE'),
        types.SafetySetting(category='HARM_CATEGORY_DANGEROUS_CONTENT', threshold='BLOCK_MEDIUM_AND_ABOVE'),
    ]
    generation_config = types.GenerateContentConfig(
        safety_settings=safety_settings_types
        # Adicionar outros parâmetros como temperature se necessário no prompt
    )

    try:
        logging.info(f"Chamando a API Gemini ({GEMINI_MODEL_NAME}) para processar '{input_filename}'...")
        response = genai_client.models.generate_content(
            model=GEMINI_MODEL_NAME,
            contents=contents,
            config=generation_config
        )
        logging.info(f"Resposta recebida da API Gemini para '{input_filename}'.")
        if response.text:
             return response.text
        else:
             logging.warning(f"Resposta da API Gemini para '{input_filename}' não contém texto. Verifique o prompt feedback:")
             if hasattr(response, 'prompt_feedback'):
                 logging.warning(f"{response.prompt_feedback}")
             else:
                 logging.warning("Prompt feedback não disponível na resposta.")
             return None
    except Exception as e:
        logging.error(f"Erro ao chamar a API Gemini para processar '{input_filename}': {e}")
        return None

# --- Função para escrever resultado em novo arquivo ---
def write_output_to_new_note(output_text: str, output_folder_path: pathlib.Path, original_filename: str):
    """
    Cria um novo arquivo .md na pasta de saída com o mesmo nome do original
    e escreve o texto de saída nele, limpando blocos de código.

    Args:
        output_text: O conteúdo a ser escrito.
        output_folder_path: O caminho (Path object) para a pasta de saída.
        original_filename: O nome do arquivo original (com extensão).
    """
    try:
        # Limpeza da resposta da IA (remove ```)
        cleaned_output = output_text.strip()
        lines = cleaned_output.splitlines()
        if lines and lines[0].strip().startswith("```"):
            lines = lines[1:]
            cleaned_output = "\n".join(lines)
        if lines and lines[-1].strip() == "```":
            lines = lines[:-1]
            cleaned_output = "\n".join(lines).strip()

        # Garante que a pasta de destino exista
        output_folder_path.mkdir(parents=True, exist_ok=True)
        logging.info(f"Pasta de destino para saída verificada/criada: {output_folder_path}")

        # Define o caminho completo do arquivo de saída
        output_file_path = output_folder_path / original_filename

        # Escreve o conteúdo limpo no novo arquivo (sobrescreve se já existir)
        output_file_path.write_text(cleaned_output, encoding='utf-8')
        logging.info(f"Saída da IA escrita com sucesso em: {output_file_path}")

    except Exception as e:
        logging.error(f"Erro ao criar ou escrever no arquivo de saída {original_filename}: {e}")


# --- Lógica Principal ---

def main(args):
    """
    Função principal do script - Foco em processar um arquivo único.
    """
    logging.info(f"Iniciando script - MODO: Processar Arquivo Único.")
    logging.info(f"Arquivo de Entrada: {args.input_file}")
    logging.info(f"Arquivo de Prompt: {args.prompt_file}")

    if not client:
         logging.critical("Cliente da API Gemini não inicializado. Script não pode continuar.")
         return

    # --- Validação dos Caminhos de Entrada ---
    input_file_path = pathlib.Path(args.input_file)
    prompt_file_path = pathlib.Path(args.prompt_file)

    if not input_file_path.is_file():
        logging.critical(f"Erro: Arquivo de entrada não encontrado ou não é um arquivo: {input_file_path}")
        return
    if not prompt_file_path.is_file():
        logging.critical(f"Erro: Arquivo de prompt não encontrado ou não é um arquivo: {prompt_file_path}")
        return

    # --- Leitura dos Arquivos ---
    logging.info(f"Lendo arquivo de entrada: {input_file_path.name}")
    _, input_content = read_note_content(input_file_path) # Ignora metadados por enquanto
    if input_content is None:
        logging.error(f"Falha ao ler o conteúdo do arquivo de entrada. Abortando.")
        return

    logging.info(f"Lendo arquivo de prompt: {prompt_file_path.name}")
    # Para o prompt, podemos ler diretamente como texto
    try:
        prompt_instructions = prompt_file_path.read_text(encoding='utf-8')
    except Exception as e:
        logging.error(f"Falha ao ler o conteúdo do arquivo de prompt: {e}. Abortando.")
        return

    # --- Processamento com IA ---
    ai_output_text = process_content_with_gemini(client, input_content, prompt_instructions, input_file_path.name)

    # --- Escrita do Resultado ---
    if ai_output_text:
        output_folder_full_path = VAULT_PATH / OUTPUT_FOLDER_RELATIVE_PATH
        # Usa o mesmo nome do arquivo de entrada para o arquivo de saída
        write_output_to_new_note(ai_output_text, output_folder_full_path, input_file_path.name)
    else:
        logging.warning("Não foi possível gerar a saída da IA.")

    logging.info("Script concluído.")

# --- Execução e Argumentos da Linha de Comando ---
if __name__ == "__main__":
    # Configura o parser de argumentos
    parser = argparse.ArgumentParser(description="Processa um arquivo Markdown do Obsidian usando a API Gemini com um prompt específico.")
    parser.add_argument("input_file", help="Caminho completo para o arquivo .md de entrada a ser processado.")
    parser.add_argument("prompt_file", help="Caminho completo para o arquivo .md contendo o prompt/instruções para a IA.")

    # Parseia os argumentos fornecidos
    args = parser.parse_args()

    try:
        main(args) # Passa os argumentos para a função principal
    except Exception as e:
        logging.critical(f"Erro fatal não tratado na execução principal: {e}", exc_info=True)


```